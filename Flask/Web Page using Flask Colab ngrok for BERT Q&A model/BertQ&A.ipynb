!pip install transformers torch ngrok pyngrok==4.1.1 flask-ngrok -q

import os
import time
from transformers import AutoModelForQuestionAnswering, AutoTokenizer
from flask import Flask, flash, request, redirect, url_for, render_template
from werkzeug.utils import secure_filename
from flask import send_from_directory
import torch
from flask_ngrok import run_with_ngrok
from pyngrok import ngrok

app = Flask(__name__, template_folder='/content/drive/MyDrive/Colab_Notebooks/template')
port_no = 5000

ngrok.set_auth_token("2Tn3V2So4kwAVQb8B55qh5fepQ2_XPixtQM384buqqS39qJH")
# public_url = ngrok.connect(port_no).public_url

model_name = 'deepset/deberta-v3-large-squad2'
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForQuestionAnswering.from_pretrained(model_name)

@app.route("/", methods=["GET", "POST"])
def home():
    if request.method == "POST":
        paragraph = request.form.get("paragraph")
        question = request.form.get("question")
        answer_gpu, time_taken_gpu = perform_qa(paragraph, question, device='cuda')
        answer_cpu, time_taken_cpu = perform_qa(paragraph, question, device='cpu')
        percent_fast = ((time_taken_cpu - time_taken_gpu) / time_taken_cpu) * 100
        return render_template(
            "index.html",
            answer_gpu=answer_gpu,
            time_taken_gpu=time_taken_gpu,
            time_taken_cpu=time_taken_cpu,
            percent_fast=percent_fast
        )
    return render_template("index.html")

def perform_qa(paragraph, question, device='cpu'):
    inputs = tokenizer(question, paragraph, add_special_tokens=True, return_tensors='pt')
    model.to(device)
    inputs.to(device)
    start_time = time.time()
    outputs = model(**inputs)
    end_time = time.time()
    processing_time = end_time - start_time
    start_scores, end_scores = outputs.start_logits, outputs.end_logits
    start_index = torch.argmax(start_scores)
    end_index = torch.argmax(end_scores)
    answer_tokens = inputs['input_ids'][0][start_index:end_index+1]
    answer = tokenizer.decode(answer_tokens)
    return answer, processing_time


run_with_ngrok(app)
app.run()
